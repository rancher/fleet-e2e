# This workflow is a reusable one called by other workflows
name: (template) Fleet E2E tests

on:
  workflow_call:
    # Variables to set when calling this reusable workflow
    secrets:
      credentials:
        description: Credentials to use to connect
        required: true
      rancher_password:
        description: Password for Rancher
        required: true
      pat_token:
        # A token is needed to be able to add runner on the repo, maybe this can be changed later
        # This token is linked to a personal account
        # So in case of token issue you have to check (no specific order and for example):
        # - the expiration date
        # - if the account associated still exists
        # - if the person still has access to the repo
        description: PAT token used to add runner
        required: true
      gitlab_private_user:
        description: Gitlab username for private repo tests
        required: false
      gitlab_private_pwd:
        description: Gitlab password for private repo tests
        required: false
      bitbucket_private_user:
        description: Bitbucket username for private repo tests
        required: false
      bitbucket_private_pwd:
        description: Bitbucket password for private repo tests
        required: false
      gh_private_user:
        description: Github username for private repo tests
        required: false
      gh_private_pwd:
        description: Github password for private repo tests
        required: false
      azure_private_user:
        description: Azure username for private repo tests
        required: false
      azure_private_pwd:
        description: Azure password for private repo tests
        required: false
      rsa_private_key_qa:
        description: RSA private key for private repo tests
        required: false
      rsa_public_key_qa:
        description: RSA public key for private repo tests
        required: false
      qase_api_token:
        description: Qase API token to use for Qase reporting
        required: true
    inputs:
      branch:
        description: Specify branch name to run workflow on
        type: string
        required: false
      cluster_name:
        description: Name of the provisioned cluster
        type: string
      destroy_runner:
        description: Destroy the auto-generated self-hosted runner
        default: true
        type: boolean
      qase_run_id:
        description: Case run ID where the results will be reported
        type: string
      rancher_version:
        description: Rancher Manager channel/version/head_version to use for installation
        default: stable/latest/none
        type: string
      upgrade:
        description: Proceed with Rancher Upgrade (True/False)
        default: true
        type: boolean
      rancher_upgrade:
        description: Rancher Manager channel/version to upgrade to
        type: string
      grep_test_by_tag:
        description: Grep tags. For multiple selection separate with spaces
        required: false
        type: string
        default: '@login @p0 @p1 @p1_2 @rbac'
      hardening:
        description: Select if desired hardened cluster (if 'true' use only @login @hardening-tests)
        required: false
        type: boolean
        default: false
      runner_template:
        description: Runner template to use
        # Another template available on GCP: fleet-qa-e2e-ci-runner-spot-leap-15-4-x86-64-template-v1
        default: fleet-qa-e2e-ci-runner-spot-leap-15-5-x86-64-template-v1
        type: string
      test_description:
        description: Short description of the test
        default: A description
        type: string
      upstream_cluster_version:
        description: K3s upstream cluster version where to install Rancher
        default: v1.28.8+k3s1
        type: string
        required: true
      zone:
        description: GCP zone to host the runner
        default: us-east4-a
        type: string

jobs:
  create-runner:
    runs-on: ubuntu-latest
    outputs:
      uuid: ${{ steps.generator.outputs.uuid }}
      runner: ${{ steps.generator.outputs.runner }}
      public_dns: ${{ steps.dns.outputs.public_dns }}
    steps:
      # actions/checkout MUST come before auth
      - name: Checkout
        uses: actions/checkout@v4
      - name: Generate UUID and Runner hostname
        id: generator
        run: |
          UUID=$(uuidgen)
          GH_REPO_FULL=${{ github.repository }}
          GH_REPO=${GH_REPO_FULL#*/}
          echo "uuid=${UUID//-}" >> ${GITHUB_OUTPUT}
          echo "runner=${GH_REPO//\//-}-ci-${UUID//-}" >> ${GITHUB_OUTPUT}
      - name: Authenticate to GCP
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.credentials }}
      - name: Setup gcloud
        uses: google-github-actions/setup-gcloud@v2
      - name: Create runner
        run: |
          gcloud compute instances create ${{ steps.generator.outputs.runner }} \
            --source-instance-template ${{ inputs.runner_template }} \
            --zone ${{ inputs.zone }}
      - name: Create PAT token secrets
        run: |
          echo -n ${{ secrets.pat_token }} \
            | gcloud secrets create PAT_TOKEN_${{ steps.generator.outputs.uuid }} --ttl="18000s" --quiet --data-file=-
          echo -n ${{ github.repository }} \
            | gcloud secrets create GH_REPO_${{ steps.generator.outputs.uuid }} --ttl="18000s" --quiet --data-file=-
      - name: Get public dns name in GCP
        id: dns
        run: |
          for ((i=0; i<10; i++)); do
            PUBLIC_IP=$(gcloud compute instances list --format="value(EXTERNAL_IP)" \
              --filter="name=${{ steps.generator.outputs.runner }}" 2> /dev/null)
            [[ -n "${PUBLIC_IP}" ]] && break
            sleep 2
          done
          PUBLIC_DNS=$(dig -x ${PUBLIC_IP} +short 2> /dev/null | sed 's/\.$//')
          echo "public_dns=${PUBLIC_DNS}" >> ${GITHUB_OUTPUT}
          # Raise an error if either IP and/or DNS are empty
          if [[ -z "${PUBLIC_IP}" || -z "${PUBLIC_DNS}" ]]; then
            echo "PUBLIC_IP and/or PUBLIC_DNS are empty!" >&2
            false
          fi

  pre-qase:
    runs-on: ubuntu-latest
    env:
      QASE_API_TOKEN: ${{ secrets.qase_api_token }}
      QASE_PROJECT_CODE: FLEET
    outputs:
      qase_run_description: ${{ steps.qase.outputs.qase_run_description }}
      qase_run_id: ${{ steps.qase.outputs.qase_run_id }}
      qase_run_name: ${{ steps.qase.outputs.qase_run_name }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Go
        uses: actions/setup-go@v5
        with:
          cache-dependency-path: tests/go.sum
          go-version-file: tests/go.mod

      - name: Create/Export Qase Run
        id: qase
        env:
          QASE_RUN_NAME: ${{ github.event_name == 'workflow_dispatch' && inputs.rancher_version || github.workflow }}
        run: |
          case ${{ inputs.qase_run_id }} in
            'auto')
              # Define and export URL of GH test run in Qase run description
              GH_RUN_URL="${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"
              QASE_DESC="${{ inputs.test_description }} (${GH_RUN_URL})"
              export QASE_RUN_DESCRIPTION="${QASE_DESC}"

              # Use full rancher version
              QASE_RUN_NAME=$(echo $QASE_RUN_NAME | grep -P '[0-9]+\.[0-9]+\.[0-9]+(-[a-z]+[0-9]+)?' || true)
              # Or workflow name if the full rancher version is not found
              if [ -z "$QASE_RUN_NAME" ]; then
                QASE_RUN_NAME="${{ github.workflow }}"
              fi

              # Create a Qase run, get its ID
              ID=$(cd tests && make create-qase-run)

              # Export outputs for future use
              echo "qase_run_description=${QASE_DESC}" >> ${GITHUB_OUTPUT}
              echo "qase_run_id=${ID}" >> ${GITHUB_OUTPUT}
              echo "qase_run_name=${QASE_RUN_NAME}" >> ${GITHUB_OUTPUT}

              # Just an info for debugging purposes
              echo -e "Exported values:\nQASE_RUN_ID=${ID}\nQASE_RUN_DESCRIPTION=${QASE_DESC}\nQASE_RUN_NAME=${QASE_RUN_NAME}"
              ;;
            'none')
              echo "qase_run_id=" >> ${GITHUB_OUTPUT}
              echo "### Test not reported in QASE!" >> ${GITHUB_STEP_SUMMARY}
              ;;
            [0-9]*)
              # If the run ID has been specified
              echo "qase_run_id=${{ inputs.qase_run_id }}" >> ${GITHUB_OUTPUT}
              ;;
          esac

  e2e:
    needs: [create-runner, pre-qase]
    runs-on: ${{ needs.create-runner.outputs.uuid }}
    env:
      DS_CLUSTER_COUNT: 3
      ARCH: amd64
      INSTALL_K3S_VERSION: ${{ inputs.upstream_cluster_version }}
      K3S_KUBECONFIG_MODE: 0644
      # For Rancher Manager
      RANCHER_VERSION: ${{ inputs.rancher_version }}
      # For Rancher Manager Upgrade
      RANCHER_UPGRADE: ${{ inputs.rancher_upgrade }}
      UPGRADE: ${{ inputs.upgrade }}
      TIMEOUT_SCALE: 3
      # K8s Version Upgrade
      K8S_VERSION_UPGRADE_DS_CLUSTER: ${{ inputs.k8s_version_upgrade_ds_cluster }}
      K8S_VERSION_UPGRADE_DS_CLUSTER_TO: ${{ inputs.k8s_version_to_upgrade_ds_cluster_to }}
      # QASE variables
      QASE_API_TOKEN: ${{ secrets.qase_api_token }}
      QASE_PROJECT_CODE: FLEET
      QASE_RUN_ID: ${{ needs.pre-qase.outputs.qase_run_id }}
      # NOTE: this REPORT var is needed for Cypress!
      QASE_REPORT: 1
    steps:
      - name: Adding /usr/local/bin into PATH
        run: echo "/usr/local/bin/" >> ${GITHUB_PATH}
      - name: Install latest helm-3 on runner
        run: |
          echo "::group::Install git and helm-3"
          sudo zypper -n install --no-recommends git
          curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash
          echo "::endgroup::"
      - name: Checkout
        uses: actions/checkout@v4
      - name: Install Go
        uses: actions/setup-go@v5
        with:
          cache: false
          go-version-file: tests/go.mod
      - name: Checkout
        if: ${{ inputs.branch }}
        uses: actions/checkout@v4
        with:
          ref: ${{ inputs.branch }}
      - name: Install Node
        uses: actions/setup-node@v4
        with:
          node-version: 20
      - name: Install prerequisite components
        env:
          PUBLIC_DNS: ${{ needs.create-runner.outputs.public_dns }}
          PUBLIC_DOMAIN: bc.googleusercontent.com
          RANCHER_PASSWORD: ${{ secrets.rancher_password }}
        run: |
          if: ${{ inputs.hardening == 'true' }} then
            cd tests && make install-rke2-hardened-rancher
          else:
              cd tests && make e2e-install-rancher
          fi
      - name: Extract component versions/informations
        id: component
        run: |
          # Extract helm version
          HELM_VERSION=$(helm version --template='{{.Version}}' 2> /dev/null)
          # Extract CertManager version
          CERT_MANAGER_VERSION=$(kubectl get pod \
            --namespace cert-manager \
            -l app=cert-manager \
            -o jsonpath={.items[*].status.containerStatuses[*].image} 2> /dev/null || true)
          # Extract Rancher Manager version
          RM_VERSION=$(kubectl get pod \
            --namespace cattle-system \
            -l app=rancher \
            -o jsonpath={.items[*].status.containerStatuses[*].image} 2> /dev/null || true)
          # Extract Fleet App version and images from local cluster
          FLEET_APP_VERSION="$(helm list -n cattle-fleet-system -o json 2> /dev/null | jq -r '.[0] | .chart')"
          for ns in {cattle-fleet-system,cattle-fleet-local-system}; do
            FLEET_IMAGES+="$(kubectl get pods -n $ns -o jsonpath='{.items[*].spec.containers[*].image}' 2> /dev/null) "
          done
          # Export values
          echo "helm_version=${HELM_VERSION}" >> ${GITHUB_OUTPUT}
          echo "cert_manager_version=${CERT_MANAGER_VERSION}" >> ${GITHUB_OUTPUT}
          echo "rm_version=${RM_VERSION}" >> ${GITHUB_OUTPUT}
          echo "fleet_app_version=${FLEET_APP_VERSION}" >> ${GITHUB_OUTPUT}
          echo "fleet_images=${FLEET_IMAGES}" >> ${GITHUB_OUTPUT}
      - name: Cypress tests - Basics
        env:
          BROWSER: chrome
          CYPRESS_DOCKER: 'cypress/included:13.16.0'
          RANCHER_URL: https://${{ needs.create-runner.outputs.public_dns }}/dashboard
          RANCHER_USER: admin
          RANCHER_PASSWORD: ${{ secrets.rancher_password }}
          GITLAB_PRIVATE_USER: ${{ secrets.gitlab_private_user }}
          GITLAB_PRIVATE_PWD: ${{ secrets.gitlab_private_pwd }}
          BITBUCKET_PRIVATE_USER: ${{ secrets.bitbucket_private_user }}
          BITBUCKET_PRIVATE_PWD: ${{ secrets.bitbucket_private_pwd }}
          GH_PRIVATE_USER: ${{ secrets.gh_private_user }}
          GH_PRIVATE_PWD: ${{ secrets.gh_private_pwd }}
          AZURE_PRIVATE_USER: ${{ secrets.azure_private_user }}
          AZURE_PRIVATE_PWD: ${{ secrets.azure_private_pwd }}
          RSA_PRIVATE_KEY_QA: ${{ secrets.rsa_private_key_qa }}
          RSA_PUBLIC_KEY_QA: ${{ secrets.rsa_public_key_qa }}
          GREPTAGS: ${{ inputs.grep_test_by_tag }}
          UPGRADE: 'false'
          # Add cypress/e2e/unit_tests/user.spec.ts again when implementing RBAC tests.
          SPEC: |
            cypress/e2e/unit_tests/first_login_rancher.spec.ts
            cypress/e2e/unit_tests/p0_fleet.spec.ts
            cypress/e2e/unit_tests/p1_fleet.spec.ts
            cypress/e2e/unit_tests/p1_2_fleet.spec.ts
            cypress/e2e/unit_tests/rbac_fleet.spec.ts
            cypress/e2e/unit_tests/upgrade_fleet.spec.ts
        run: |
          if ${{ inputs.qase_run_id == 'none' }}; then
            # Unset default QASE_* variables when reporting is disabled
            unset QASE_REPORT
            unset QASE_API_TOKEN
            # QASE_RUN_ID is empty string already
          fi
          cd tests && make start-cypress-tests
      - name: Upload Cypress screenshots (Basics)
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: cypress-screenshots-basics-${{ inputs.cluster_name }}
          path: tests/cypress/screenshots
          retention-days: 7
          if-no-files-found: ignore
      - name: Upload Cypress videos (Basics)
        # Test run video is always captured, so this action uses "always()" condition
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: cypress-videos-basics-${{ inputs.cluster_name }}
          path: tests/cypress/videos
          retention-days: 7
      - name: Upgrade Rancher Manager
        id: rancher_upgrade
        if: ${{ inputs.rancher_upgrade != '' }}
        env:
          PUBLIC_DNS: ${{ needs.create-runner.outputs.public_dns }}
          PUBLIC_DOMAIN: bc.googleusercontent.com
          RANCHER_UPGRADE: ${{ inputs.rancher_upgrade }}
        run: |
          cd tests

          if make e2e-upgrade-rancher-manager; then
            # Extract Rancher Manager version
            RANCHER_VERSION=$(kubectl get pod \
                                --namespace cattle-system \
                                -l app=rancher \
                                -o jsonpath={.items[*].status.containerStatuses[*].image} 2> /dev/null || true)

            # Export values
            echo "rancher_image_version=${RANCHER_VERSION}" >> ${GITHUB_OUTPUT}

          else
            # Needed to be sure that Github Action will see the failure
            false
          fi
      - name: Extract component versions/informations after Upgrade
        id: upgraded_component
        run: |
          # Extract Rancher Manager version
          RM_UPGRADED_VERSION=$(kubectl get pod \
            --namespace cattle-system \
            -l app=rancher \
            -o jsonpath={.items[*].status.containerStatuses[*].image} 2> /dev/null || true)
          # Extract Fleet App version and images from local cluster
          FLEET_APP_UPGRADED_VERSION="$(helm list -n cattle-fleet-system -o json 2> /dev/null | jq -r '.[0] | .chart')"
          for ns in {cattle-fleet-system,cattle-fleet-local-system}; do
            FLEET_UPGRADED_IMAGES+="$(kubectl get pods -n $ns -o jsonpath='{.items[*].spec.containers[*].image}' 2> /dev/null) "
          done
          # Export values
          echo "rm_upgraded_version=${RM_UPGRADED_VERSION}" >> ${GITHUB_OUTPUT}
          echo "fleet_app_upgraded_version=${FLEET_APP_UPGRADED_VERSION}" >> ${GITHUB_OUTPUT}
          echo "fleet_images_after_upgrade=${FLEET_UPGRADED_IMAGES}" >> ${GITHUB_OUTPUT}
      - name: Cypress tests - On Upgraded Rancher
        id: cypress_result_after_rancher_upgrade
        if: ${{ inputs.rancher_upgrade != '' }}
        env:
          BROWSER: chrome
          CYPRESS_DOCKER: 'cypress/included:13.16.0'
          RANCHER_URL: https://${{ needs.create-runner.outputs.public_dns }}/dashboard
          RANCHER_USER: admin
          RANCHER_PASSWORD: ${{ secrets.rancher_password }}
          GITLAB_PRIVATE_USER: ${{ secrets.gitlab_private_user }}
          GITLAB_PRIVATE_PWD: ${{ secrets.gitlab_private_pwd }}
          BITBUCKET_PRIVATE_USER: ${{ secrets.bitbucket_private_user }}
          BITBUCKET_PRIVATE_PWD: ${{ secrets.bitbucket_private_pwd }}
          GH_PRIVATE_USER: ${{ secrets.gh_private_user }}
          GH_PRIVATE_PWD: ${{ secrets.gh_private_pwd }}
          AZURE_PRIVATE_USER: ${{ secrets.azure_private_user }}
          AZURE_PRIVATE_PWD: ${{ secrets.azure_private_pwd }}
          RSA_PRIVATE_KEY_QA: ${{ secrets.rsa_private_key_qa }}
          RSA_PUBLIC_KEY_QA: ${{ secrets.rsa_public_key_qa }}
          GREPTAGS: ${{ inputs.grep_test_by_tag }}
          UPGRADE: ${{ inputs.upgrade }}
          FLEET_APP_VERSION: ${{ steps.component.outputs.fleet_app_version }}
          RANCHER_VERSION: ${{ inputs.rancher_upgrade }}
          K8S_VERSION_UPGRADE_DS_CLUSTER: ${{ inputs.k8s_version_upgrade_ds_cluster }}
          K8S_VERSION_UPGRADE_DS_CLUSTER_TO: ${{ inputs.k8s_version_to_upgrade_ds_cluster_to }}
          SPEC: |
            cypress/e2e/unit_tests/first_login_rancher.spec.ts
            cypress/e2e/unit_tests/upgrade_fleet.spec.ts
        run: |
          if ${{ inputs.qase_run_id == 'none' }}; then
            # Unset default QASE_* variables when reporting is disabled
            unset QASE_REPORT
            unset QASE_API_TOKEN
            # QASE_RUN_ID is empty string already
          fi
          cd tests && make start-cypress-tests
      - name: Upload Cypress screenshots (after-upgrade)
        if: failure() && ${{ inputs.rancher_upgrade != '' }}
        uses: actions/upload-artifact@v4
        with:
          name: cypress-screenshots-after-upgrade-${{ inputs.cluster_name }}
          path: tests/cypress/screenshots
          retention-days: 7
          if-no-files-found: ignore
      - name: Upload Cypress videos (after-upgrade)
        if: ${{ inputs.rancher_upgrade != '' }}
        uses: actions/upload-artifact@v4
        with:
          name: cypress-videos-after-upgrade-${{ inputs.cluster_name }}
          path: tests/cypress/videos
          retention-days: 7
      - name: Upload webhook setup log
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: webhook-setup-log-${{ inputs.cluster_name }}
          path: tests/assets/webhook-tests/webhook_setup.log
      - name: Add summary
        if: ${{ always() }}
        run: |
          echo "## General information" >> ${GITHUB_STEP_SUMMARY}
          echo -e "***${{ inputs.test_description }}***\n" >> ${GITHUB_STEP_SUMMARY}
          echo "Type of cluster deployed: ${CLUSTER_TYPE:-normal}" >> ${GITHUB_STEP_SUMMARY}
          echo "Helm version: ${{ steps.component.outputs.helm_version}}" >> ${GITHUB_STEP_SUMMARY}
          echo "### Rancher Manager" >> ${GITHUB_STEP_SUMMARY}
          echo "Rancher Manager Image: ${{ steps.component.outputs.rm_version }}" >> ${GITHUB_STEP_SUMMARY}
          echo "Rancher Manager Version: ${{ inputs.rancher_version }}" >> ${GITHUB_STEP_SUMMARY}
          echo "CertManager Image: ${{ steps.component.outputs.cert_manager_version }}" >> ${GITHUB_STEP_SUMMARY}
          echo "### Fleet" >> ${GITHUB_STEP_SUMMARY}
          echo "Fleet App version: ${{ steps.component.outputs.fleet_app_version }}" >> ${GITHUB_STEP_SUMMARY}
          echo "Fleet images in local cluster: ${{ steps.component.outputs.fleet_images }}" >> ${GITHUB_STEP_SUMMARY}
          echo "### Kubernetes" >> ${GITHUB_STEP_SUMMARY}
          echo "K3s version for Rancher Manager: ${{ env.INSTALL_K3S_VERSION }}" >> ${GITHUB_STEP_SUMMARY}
          echo "K3d version for downstream cluster: ${{ env.INSTALL_K3S_VERSION }}" >> ${GITHUB_STEP_SUMMARY}
          if ${{ inputs.rancher_upgrade != '' }}; then
            echo "### Rancher Manager Upgrade Information" >> ${GITHUB_STEP_SUMMARY}
            echo "Rancher Manager Installed Version: ${{ steps.component.outputs.rm_version }}" >> ${GITHUB_STEP_SUMMARY}
            echo "Rancher Manager Upgraded Version: ${{ steps.upgraded_component.outputs.rm_upgraded_version }}" >> ${GITHUB_STEP_SUMMARY}
            echo "### Fleet (After Upgrade)" >> ${GITHUB_STEP_SUMMARY}
            echo "Fleet App version: ${{ steps.upgraded_component.outputs.fleet_app_upgraded_version }}" >> ${GITHUB_STEP_SUMMARY}
            echo "Fleet images in local cluster: ${{ steps.upgraded_component.outputs.fleet_images_after_upgrade }}" >> ${GITHUB_STEP_SUMMARY}
          fi

  delete-runner:
    if: ${{ always() && inputs.destroy_runner == true }}
    needs: [create-runner, e2e]
    runs-on: ubuntu-latest
    steps:
      # actions/checkout MUST come before auth
      - name: Checkout
        uses: actions/checkout@v4
      - name: Authenticate to GCP
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.credentials }}
      - name: Setup gcloud
        uses: google-github-actions/setup-gcloud@v2
      - name: Delete PAT token secrets
        run: |
          gcloud --quiet secrets delete PAT_TOKEN_${{ needs.create-runner.outputs.uuid }} || true
          gcloud --quiet secrets delete GH_REPO_${{ needs.create-runner.outputs.uuid }} || true
      - name: Delete runner
        run: |
          gcloud --quiet compute instances delete ${{ needs.create-runner.outputs.runner }} \
            --delete-disks all \
            --zone ${{ inputs.zone }}

  post-qase:
    if: ${{ always() && needs.pre-qase.outputs.qase_run_id != '' }}
    needs: [e2e, pre-qase]
    runs-on: ubuntu-latest
    env:
      QASE_API_TOKEN: ${{ secrets.qase_api_token }}
      QASE_PROJECT_CODE: FLEET
      QASE_REPORT: 1
      QASE_RUN_COMPLETE: 1
      QASE_RUN_ID: ${{ needs.pre-qase.outputs.qase_run_id }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Go
        uses: actions/setup-go@v5
        with:
          cache-dependency-path: tests/go.sum
          go-version-file: tests/go.mod

      - name: Finalize Qase Run and publish Results
        if: ${{ always() && !contains(needs.e2e.result, 'cancelled') }}
        run: |
          REPORT=$(cd tests && make publish-qase-run)
          echo "${REPORT}"

          # Extract report URL and put it in summary
          REPORT_URL=$(awk '/available:/ { print $NF }' <<<${REPORT})
          if [[ -n "${REPORT_URL}" ]]; then
            echo "## QASE Reporting" >> ${GITHUB_STEP_SUMMARY}
            echo "Public Qase report: ${REPORT_URL}" >> ${GITHUB_STEP_SUMMARY}
          fi

      - name: Delete Qase Run if job has been cancelled
        if: ${{ always() && contains(needs.e2e.result, 'cancelled') }}
        run: cd tests && make delete-qase-run

  # Just to signify that something has been cancelled and it's not useful to check the test
  declare-cancelled:
    if: ${{ always() && contains(needs.e2e.result, 'cancelled') }}
    needs: e2e
    runs-on: ubuntu-latest
    steps:
      - name: Specify in summary if something has been cancelled
        run: echo "# TEST CANCELLED!" >> ${GITHUB_STEP_SUMMARY}
